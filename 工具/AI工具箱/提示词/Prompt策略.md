
### 基于底层原理的 Prompt 设计思维
**核心原则：你的目标是"缩小模型的预测空间"**
回想 2.4 节的内容：LLM 是在预测"下一个最可能的 Token"。Prompt 的作用是影响这个概率分布。好的 Prompt 能让"正确答案"的概率大幅上升。
```
模糊 Prompt → 概率分布扁平 → 各种输出都可能 → 结果不可控
精确 Prompt → 概率分布尖锐 → 目标输出概率高 → 结果可控
```
### 策略一：明确角色设定（Role）

**原理依据：** 角色设定会激活模型中特定的"知识区域"和"表达模式"。

**基本模式：**
```
你是一位 [具体身份]，擅长 [具体技能]，你的特点是 [特定风格]。
```

**进阶技巧：** 角色可以叠加

```
"你是一位资深的前端工程师，同时也是一个优秀的技术文档写作者。
请用清晰的技术文档风格，解释这个 React Hook 的用法。"
```

### 策略二：清晰描述任务（Task）

**原理依据：** 任务描述越明确，模型需要"猜测"你意图的空间就越小。

**基本模式：**
```
请完成以下任务：[具体任务描述]
要求：
1. [要求1]
2. [要求2]
3. [要求3]
```

**示例对比：**

```
❌ 差："写一个排序函数"

✅ 好："请用 Python 实现一个函数：
- 函数名：merge_sort
- 功能：使用归并排序算法对列表进行升序排序
- 输入：一个包含整数的列表
- 输出：排序后的新列表（不修改原列表）
- 要求：
  1. 使用递归实现
  2. 处理空列表的情况
  3. 添加简短的注释说明关键步骤"
```


### 策略四：分步骤引导（Chain of Thought）

**原理依据：** 我们在 2.3 节学过，长链推理容易出错。把大任务拆成小步骤，可以降低累积错误的风险。

**基本模式：**
```
请按以下步骤思考：
1. 首先，[步骤1]
2. 然后，[步骤2]
3. 最后，[步骤3]
```

**或者更简单的触发词：**
```
"请一步步思考..."
"Let's think step by step..."
```
**为什么分步有效：**

- 强制模型走"正确的思考路径"
- 每一步的输出作为下一步的输入，减少跳跃式推理
- 中间步骤暴露出来，方便发现问题在哪

### 构建自己的工作流：思考框架

当你想用 AI Agent 完成一个复杂任务时，可以这样思考：

**第一步：任务分解**
```
这个任务可以拆成哪些子任务？
每个子任务的输入输出是什么？
子任务之间的依赖关系是什么？
```

**第二步：工具映射**
```
每个子任务需要什么工具？
Agent 有这个工具吗？
如果没有，能否通过组合现有工具实现？
```

**第三步：设计检查点**
```
哪些步骤容易出错？
在哪里设置验证？
出错了怎么处理？
```

**第四步：编写指令**
```
把以上思考转化为清晰的 Prompt
包含：目标、步骤、约束、验证方式
```

**示例：批量重命名文件的工作流设计**

```
任务：把 src 目录下所有 .js 文件重命名为 .ts 文件

分解：
1. 找到所有 .js 文件
2. 对每个文件：
   a. 读取内容
   b. 如果内容有 JavaScript 特有语法，先转换
   c. 重命名文件为 .ts
3. 更新 import 语句
4. 运行 TypeScript 编译检查

Prompt：
"请帮我把 src 目录下的所有 .js 文件迁移到 TypeScript：
1. 首先列出所有需要处理的 .js 文件
2. 对每个文件，检查是否有需要转换的语法
3. 将文件扩展名改为 .ts
4. 更新所有受影响的 import 语句
5. 最后运行 tsc 检查是否有类型错误
如果遇到复杂的类型问题，先标记 any，我稍后手动处理"
```

---


