# 第一大块：AI Agent 框架层

> 在深入了解 AI Agent 之前，我们需要先建立一个核心认知：**AI Agent 不等于大语言模型（LLM）**。LLM 只是 Agent 的"大脑"，而 Agent 是一个完整的"智能体"——它有感知能力、有记忆、能使用工具、能规划和执行任务。就像人类不只是一个大脑，还有眼睛、手、记忆系统和行动能力一样。
>
> 这一大块，我们会拆解 Agent 这个"智能体"的核心组成部分，让你理解它是怎么"活"起来的。

---

## 1.1 Agentic Loop（Agent 的核心运转循环）


Agentic Loop分解为四个阶段：

```
感知 (Perceive) → 计划 (Plan) → 执行 (Act) → 反馈 (Observe) → 再感知...
```

在 Agentic Loop 中，"状态"（State）是指 Agent 在某一时刻掌握的所有信息的总和。它包括：

- **当前任务**：用户让我做什么
- **已完成的步骤**：我已经做了什么
- **中间结果**：每一步产生了什么结果
- **剩余目标**：还有什么没做完

每完成一次循环，状态就会更新。Agent 根据最新的状态来决定下一步动作。

停止条件：

**1. 任务完成**
Agent 判断用户的目标已经达成，主动停止。比如用户说"帮我写一个函数"，函数写完了，Agent 就停止。

**2. 达到最大轮次**
为了防止 Agent 陷入死循环，系统通常设置一个最大循环次数（比如 50 轮）。超过这个次数，强制停止。

**3. 遇到无法解决的错误**
当 Agent 反复尝试某个操作都失败，且没有其他方案时，它会停止并向用户报告问题。

**4. 用户主动中断**
用户可以随时打断 Agent 的执行。



### 为什么要循环而不是一次性完成

你可能会问：为什么不让 Agent 一次性想好所有步骤，然后批量执行呢？

原因有三：

1. **复杂任务无法预知所有情况**：就像你无法在出门前就知道路上会遇到什么，很多事情只有做了才知道结果。

2. **每一步的结果会影响下一步的决策**：如果第一步失败了，第二步的计划就需要调整。循环机制让 Agent 能够灵活应对变化。

3. **LLM 的能力有限**：大语言模型擅长处理单步推理，让它一次规划 100 步容易出错。分步执行，每步都检查，出错概率更低。

---

## 1.2 Tool Use（工具调用机制）



它通过训练学会了"读文件→用 Read 工具"、"执行代码→用 Bash 工具"这样的关联。

### 工具调用的完整流程

```
用户输入: "帮我看看 package.json 里的依赖有哪些"

[Agent 思考]
→ 需要读取 package.json 文件
→ 决定调用 Read 工具

[Agent 发起工具调用]
→ 工具名: Read
→ 参数: { file_path: "package.json" }

[系统执行工具]
→ 读取文件内容
→ 返回文件内容给 Agent

[Agent 处理结果]
→ 收到文件内容
→ 分析 dependencies 字段
→ 整理成易读的格式

[Agent 回复用户]
→ "package.json 中有以下依赖：react、lodash、axios..."
```


### Claude Code 中的 Tool Use 实例

在 Claude Code 这个 Agent 中，常用的工具包括：

| 工具名       | 功能   | 使用场景             |
| --------- | ---- | ---------------- |
| Read      | 读取文件 | 查看代码、配置文件、文档     |
| Write     | 写入文件 | 创建新文件            |
| Edit      | 编辑文件 | 修改现有文件的特定部分      |
| Bash      | 执行命令 | 运行程序、git 操作、安装依赖 |
| Glob      | 搜索文件 | 按文件名模式查找文件       |
| Grep      | 搜索内容 | 在文件中搜索特定文本       |
| WebFetch  | 获取网页 | 读取在线文档、API 响应    |
| WebSearch | 搜索网络 | 查找最新信息           |

当你让 Claude Code "帮我修复这个 bug"时，它可能会：
1. 用 **Read** 查看相关代码
2. 用 **Grep** 搜索错误信息出现的位置
3. 用 **Edit** 修改有问题的代码
4. 用 **Bash** 运行测试确认修复成功

这就是 Tool Use 在实际 Agent 中的应用。

---

## 1.3 Context Window（上下文窗口）



Context Window 里通常包含以下几类信息：

**1. 系统指令（System Prompt）**
告诉 Agent "你是谁、你该怎么做"的基础设定。比如"你是一个编程助手，帮助用户解决代码问题"。

**2. 对话历史**
用户和 Agent 之前的所有对话。包括用户说的每一句话，和 Agent 的每一次回复。

**3. 工具调用记录**
Agent 调用了什么工具、工具返回了什么结果。这些也会被记录在 Context 里。

当前用户输入

```
Context Window 的结构示意：
┌─────────────────────────────────────┐
│ [系统指令] 你是一个编程助手...        │
├─────────────────────────────────────┤
│ [用户] 帮我看看这段代码有什么问题      │
│ [Agent] 我来分析一下...              │
│ [工具调用] Read: main.py             │
│ [工具结果] def hello():...           │
│ [Agent] 这段代码的问题是...           │
│ [用户] 那怎么修复呢？                 │  ← 当前位置
├─────────────────────────────────────┤
│           (剩余空间)                  │
└─────────────────────────────────────┘
```




---

## 1.4 Memory 机制（Agent 的"记忆"）

### 长期记忆是怎么实现的

**1. 向量数据库（Vector Database）**
把文本信息转换成数字向量，存储在专门的数据库里。需要时，通过"语义搜索"找到相关的记忆。

**2. 文件存储**
把记忆直接写入文件（比如 CLAUDE.md 这样的项目记忆文件）。需要时读取文件内容。

**3. 外部知识库**
连接到文档系统、Wiki、数据库等外部知识源。


### Agent 怎么检索记忆

当 Agent 需要用到长期记忆时，它会：

1. **判断需要什么信息**："用户问的是这个项目的配置方式，我需要查一下项目文档"

2. **发起检索请求**：用关键词或语义向量去搜索记忆库

3. **获取相关记忆**：检索系统返回最相关的几条记忆

4. **放入 Context**：把检索到的记忆放入当前的 Context Window

5. **基于记忆推理**：结合记忆内容来回答问题

这个过程叫做 **RAG（Retrieval-Augmented Generation）**，即"检索增强生成"。



---

## 1.5 Planning & Reasoning（规划和推理）

### Agent 是怎么"想出"解决方案的

当 Agent 收到一个复杂任务时，它不是随便乱做，而是会进行**规划**。

规划的过程通常是：

**1. 理解目标**
"用户要我做什么？最终要达成什么结果？"

**2. 分解任务**
"这个大目标可以拆成哪些小步骤？"

**3. 确定顺序**
"这些步骤应该按什么顺序执行？有没有依赖关系？"

**4. 评估可行性**
"每一步我有能力完成吗？需要什么工具？"

**5. 形成计划**
"好，我的计划是：第一步做 A，第二步做 B，第三步做 C"

### 单步推理 vs 多步推理

**单步推理**
输入 → 直接输出答案

例子：
- 问："1+1 等于几？" 答："2"
- 问："'hello' 的中文是什么？" 答："你好"

这种问题不需要复杂思考，LLM 直接就能给出答案。

**多步推理（链式推理，Chain-of-Thought）**
输入 → 思考步骤1 → 思考步骤2 → ... → 最终答案

例子：
- 问："一个商店有 20 个苹果，卖掉 8 个，又进货 15 个，现在有几个？"
- 推理过程：
  - 原来有 20 个
  - 卖掉 8 个：20 - 8 = 12 个
  - 进货 15 个：12 + 15 = 27 个
  - 答案：27 个

Agent 做复杂任务时，基本都是多步推理。它会"想一步，做一步，再想下一步"。




---
## 3.2 用 Claude Code构建工作流的思路

### 这些工具内部是怎么组合各个组件的

让我们把第一大块学的内容和实际工具对应起来：

**Claude Code 的架构（简化版）：**

```
┌─────────────────────────────────────────────────┐
│                  Claude Code                     │
├─────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────┐   │
│  │         Agentic Loop (主循环)            │   │
│  │  ┌─────────────────────────────────┐    │   │
│  │  │ 1. 接收用户输入                  │    │   │
│  │  │ 2. LLM 分析并决策                │    │   │
│  │  │ 3. 如需要，调用工具执行          │    │   │
│  │  │ 4. 处理工具返回的结果            │    │   │
│  │  │ 5. 决定是继续还是回复用户        │    │   │
│  │  │ 6. 循环回到步骤2                 │    │   │
│  │  └─────────────────────────────────┘    │   │
│  └─────────────────────────────────────────┘   │
│                                                  │
│  ┌──────────────┐  ┌──────────────────────┐    │
│  │   LLM 核心   │  │      工具集           │    │
│  │   (Claude)   │  │  Read, Write, Edit   │    │
│  │              │  │  Bash, Grep, Glob    │    │
│  │              │  │  WebFetch, WebSearch │    │
│  └──────────────┘  └──────────────────────┘    │
│                                                  │
│  ┌──────────────────────────────────────────┐  │
│  │            Context Window                 │  │
│  │  [系统指令] [对话历史] [工具调用记录]     │  │
│  └──────────────────────────────────────────┘  │
└─────────────────────────────────────────────────┘
```

当你输入一个任务时，发生的事情是：

1. 你的输入进入 Context Window
2. LLM 基于 Context 做出判断
3. 如果需要工具，Agent 调用工具
4. 工具结果返回，加入 Context
5. LLM 继续判断下一步
6. 循环直到任务完成
## 本章小结

我们来回顾一下 AI Agent 框架层的核心要点：

| 组件                   | 核心概念           | 一句话记忆             |
| -------------------- | -------------- | ----------------- |
| Agentic Loop         | 感知→计划→执行→反馈的循环 | Agent 通过不断循环来完成任务 |
| Tool Use             | 调用外部工具扩展能力     | LLM 是大脑，工具是双手     |
| Context Window       | 模型能看到的信息范围     | Agent 的"工作台"大小有限  |
| Memory               | 短期记忆+长期记忆系统    | 工作台上的+图书馆里的       |
| Planning & Reasoning | 分解任务、多步推理、动态调整 | 像下棋一样走一步想几步       |

这五个组件共同构成了 AI Agent 的"骨架"。理解了这些，你就明白了 Agent 是怎么"活"起来的。

